# ğŸ“¡ Real-Time Environmental Sensor Data Pipeline

This project implements a real-time data pipeline using **Apache Kafka**, **Docker**, and **PostgreSQL** to simulate and process environmental sensor data from a CSV file. The pipeline mimics live IoT sensor streaming and stores the data for further analysis.

---

## ğŸš€ Project Overview

- ğŸ“ Source: Kaggle Dataset â€“ *Environmental Sensor Data (132k rows)*
- ğŸ”„ Simulates real-time sensor data with `pandas`
- ğŸ”Œ Streams data into **Kafka topics** using a Python producer
- ğŸ“¥ Kafka consumer reads the stream and stores it in **PostgreSQL**
- ğŸ³ Fully containerized with **Docker Compose**
- ğŸ“Š Kafka-UI for topic monitoring

---

## ğŸ› ï¸ Technologies Used

| Component        | Tech Stack                     |
|------------------|--------------------------------|
| Data Streaming   | Apache Kafka                   |
| Messaging System | Kafka-Python (`kafka-python`)  |
| Data Ingestion   | Python + Pandas                |
| Database         | PostgreSQL                     |
| Orchestration    | Docker + Docker Compose        |
| Monitoring       | Kafka-UI (ProvectusLabs)       |

---

## ğŸ—‚ï¸ Project Structure
```bash
elective2/
â”œâ”€â”€ dataset/
â”‚ â””â”€â”€ iot_telemetry_data.csv
â”œâ”€â”€ producer/
â”‚ â”œâ”€â”€ producer.py
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â””â”€â”€ Dockerfile
â”œâ”€â”€ consumer/
â”‚ â”œâ”€â”€ consumer.py
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â””â”€â”€ Dockerfile
â”œâ”€â”€ db/
â”‚ â””â”€â”€ init.sql
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```
---

## ğŸ§  Kafka Topic

- **Topic Name**: `kafka-topic-postgress`
- **Created Dynamically** if not already present
- Partitions: `1`
- Replication: `1`

---

## ğŸ§ª How to Run This Project

### 1. Clone the Repository

```bash
git clone https://github.com/gulomovazukhrakhon/elective2.git
cd elective2
```
### 2. Run Docker Compose
```bash
docker-compose up --build
``` 

This will start:
* Kafka + Zookeeper
* PostgreSQL
* Producer and Consumer
* Kafka-UI on port `8080`

### 3. Access Kafka UI
ğŸ“ Open: http://localhost:8080
<br>
ğŸ§  Topic: kafka-topic-postgress

---

## ğŸ—„ï¸ PostgreSQL Table: telemtry_data
Created automatically via init.sql. Structure:

| Column   | Type             |
|----------|------------------|
| ts       | DOUBLE PRECISION |
| device   | TEXT             |
| co       | DOUBLE PRECISION |
| humidity | DOUBLE PRECISION |
| light    | BOOLEAN          |
| lpg      | DOUBLE PRECISION |
| motion   | BOOLEAN          |
| smoke    | DOUBLE PRECISION |
| temp     | DOUBLE PRECISION |

---

## ğŸ” How It Works

1. producer.py reads CSV row by row
2. Sends each row as a JSON message to Kafka
3. Kafka holds messages under kafka-topic-postgress
4. consumer.py listens to the topic and inserts each message into PostgreSQL
5. Kafka UI displays messages in real-time

---

## âœ… Project Highlights

* â±ï¸ Simulated real-time streaming (5s delay)
* ğŸ’¾ Durable storage with PostgreSQL
* ğŸ›¡ï¸ Error handling and retry logic for resilience
* ğŸ”Œ Modular and scalable architecture
* ğŸ³ Fully containerized and reproducible

---

## ğŸ“š Dataset Source

[Kaggle: Environmental Sensor Data (132k rows)](https://www.kaggle.com/datasets/garystafford/environmental-sensor-data-132k)

---

## ğŸ‘©â€ğŸ’» Author

**Zukhrahon Gulomova**
<br>Applied Artificial Intelligence, IU International University
